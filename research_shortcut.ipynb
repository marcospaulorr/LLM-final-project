{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5523610",
   "metadata": {},
   "source": [
    "# ResearchShortcut: ArXiv Paper Quick Scanner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04c175a",
   "metadata": {},
   "source": [
    "### 1. Instalar dependências\n",
    "Execute (ou adapte) o comando abaixo em uma célula de **terminal** ou **notebook**:\n",
    "```bash\n",
    "pip install langchain-core langchain-community langchain-huggingface huggingface-hub arxiv pandas ipywidgets\n",
    "```\n",
    "\n",
    "> **Obs.** Todas essas bibliotecas são gratuitas e não exigem chave da OpenAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4fa8944c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install transformers sentencepiece accelerate torch --upgrade\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fac3f61",
   "metadata": {},
   "source": [
    "### 2. Configurar chave gratuita da Hugging Face\n",
    "1. Crie uma conta gratuita em https://huggingface.co.\n",
    "2. Gere um *Access Token* (Profile ▸ Settings ▸ Access Tokens).\n",
    "3. Defina a variável de ambiente antes de rodar o notebook:\n",
    "```python\n",
    "import os\n",
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"SEU_TOKEN_AQUI\"\n",
    "```\n",
    "Isso é **opcional** para modelos open‑source hospedados pela Hugging Face, mas previne limites estritos de requisições anônimas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "571757de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "713e68e535034d358f16ca7545e026f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.40k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\marco\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\marco\\.cache\\huggingface\\hub\\models--google--flan-t5-small. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cecc23fb711c436f9ac9b3227ea5e63d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/308M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbb4d79b32234606b7cee9cbf7430df1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee23dd638b024b11bb0b992766f57601",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "120628d41f9e4d2c9115156656b80602",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3f34da941f149599aec299b473a2c67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "610bd54572ef4d69b15259f93fe1451f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "C:\\Users\\marco\\AppData\\Local\\Temp\\ipykernel_13556\\2014655971.py:12: LangChainDeprecationWarning: The class `HuggingFacePipeline` was deprecated in LangChain 0.0.37 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFacePipeline``.\n",
      "  llm = HuggingFacePipeline(pipeline=pipe_small)\n"
     ]
    }
   ],
   "source": [
    "import os, pandas as pd, arxiv\n",
    "from langchain_community.llms import HuggingFaceHub\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "from transformers import pipeline\n",
    "from langchain_community.llms import HuggingFacePipeline\n",
    "\n",
    "pipe_small = pipeline(\"text2text-generation\",\n",
    "                      model=\"google/flan-t5-small\",\n",
    "                      max_new_tokens=96,\n",
    "                      device_map=\"auto\")\n",
    "llm = HuggingFacePipeline(pipeline=pipe_small)\n",
    "\n",
    "\n",
    "summary_prompt = PromptTemplate.from_template(\n",
    "    '''Você é um assistente que ajuda pesquisadores.\n",
    "    **Instrução**: Para o artigo abaixo, gere um resumo curto (máx 3 linhas) e depois uma lista de até 3 contribuições‑chave em bullets.\n",
    "    Saída no formato:\n",
    "    Resumo: <texto>\n",
    "    Contribuições:\n",
    "    - ...\n",
    "    - ...\n",
    "    - ...\n",
    "\n",
    "    Artigo:\n",
    "    {title}\n",
    "    {abstract}'''\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "108ec639",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_arxiv(query: str, max_results: int = 3):\n",
    "    \"\"\"Retorna lista de objetos arxiv.Result.\"\"\"\n",
    "    search = arxiv.Search(\n",
    "        query=query,\n",
    "        max_results=max_results,\n",
    "        sort_by=arxiv.SortCriterion.SubmittedDate,\n",
    "    )\n",
    "    return list(search.results())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f24085c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def brief_paper(paper):\n",
    "    text = summary_prompt.format(title=paper.title, abstract=paper.summary)\n",
    "    return llm.invoke(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82c5fbd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(query: str, n: int = 3):\n",
    "    \"\"\"Busca n artigos e retorna DataFrame resumido.\"\"\"\n",
    "    results = []\n",
    "    for paper in search_arxiv(query, n):\n",
    "        summary = brief_paper(paper)\n",
    "        results.append({\n",
    "            'Título': paper.title,\n",
    "            'Autores': ', '.join(a.name for a in paper.authors),\n",
    "            'Resumo & Contribuições': summary,\n",
    "            'PDF': paper.pdf_url,\n",
    "            'Publicado': paper.published.date(),\n",
    "        })\n",
    "    return pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5840a948",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marco\\AppData\\Local\\Temp\\ipykernel_13556\\2161051291.py:8: DeprecationWarning: The 'Search.results' method is deprecated, use 'Client.results' instead\n",
      "  return list(search.results())\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Título</th>\n",
       "      <th>Autores</th>\n",
       "      <th>Resumo &amp; Contribuições</th>\n",
       "      <th>PDF</th>\n",
       "      <th>Publicado</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Modeling Cosmic-Ray Transport: Magnetized vers...</td>\n",
       "      <td>Jeremiah Lübke, Patrick Reichherzer, Sophie Ae...</td>\n",
       "      <td>Our results highlight the critical role of coh...</td>\n",
       "      <td>http://arxiv.org/pdf/2505.18155v1</td>\n",
       "      <td>2025-05-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Staircase of Ethics: Probing LLM Value Pri...</td>\n",
       "      <td>Ya Wu, Qiang Sheng, Danding Wang, Guang Yang, ...</td>\n",
       "      <td>We introduce the Multi-step Moral Dilemmas, th...</td>\n",
       "      <td>http://arxiv.org/pdf/2505.18154v1</td>\n",
       "      <td>2025-05-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>REN: Fast and Efficient Region Encodings from ...</td>\n",
       "      <td>Savya Khosla, Sethuraman TV, Barnett Lee, Alex...</td>\n",
       "      <td>We introduce the Region Encoder Network (REN),...</td>\n",
       "      <td>http://arxiv.org/pdf/2505.18153v1</td>\n",
       "      <td>2025-05-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fann or Flop: A Multigenre, Multiera Benchmark...</td>\n",
       "      <td>Wafa Alghallabi, Ritesh Thawkar, Sara Ghaboura...</td>\n",
       "      <td>Fann or Flop, the first benchmark designed to ...</td>\n",
       "      <td>http://arxiv.org/pdf/2505.18152v1</td>\n",
       "      <td>2025-05-23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Título  \\\n",
       "0  Modeling Cosmic-Ray Transport: Magnetized vers...   \n",
       "1  The Staircase of Ethics: Probing LLM Value Pri...   \n",
       "2  REN: Fast and Efficient Region Encodings from ...   \n",
       "3  Fann or Flop: A Multigenre, Multiera Benchmark...   \n",
       "\n",
       "                                             Autores  \\\n",
       "0  Jeremiah Lübke, Patrick Reichherzer, Sophie Ae...   \n",
       "1  Ya Wu, Qiang Sheng, Danding Wang, Guang Yang, ...   \n",
       "2  Savya Khosla, Sethuraman TV, Barnett Lee, Alex...   \n",
       "3  Wafa Alghallabi, Ritesh Thawkar, Sara Ghaboura...   \n",
       "\n",
       "                              Resumo & Contribuições  \\\n",
       "0  Our results highlight the critical role of coh...   \n",
       "1  We introduce the Multi-step Moral Dilemmas, th...   \n",
       "2  We introduce the Region Encoder Network (REN),...   \n",
       "3  Fann or Flop, the first benchmark designed to ...   \n",
       "\n",
       "                                 PDF   Publicado  \n",
       "0  http://arxiv.org/pdf/2505.18155v1  2025-05-23  \n",
       "1  http://arxiv.org/pdf/2505.18154v1  2025-05-23  \n",
       "2  http://arxiv.org/pdf/2505.18153v1  2025-05-23  \n",
       "3  http://arxiv.org/pdf/2505.18152v1  2025-05-23  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = run('large language model evaluation', 4)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4a0bb3",
   "metadata": {},
   "source": [
    "### 3. Próximos passos sugeridos\n",
    "- **Melhorar prompt** para controlar tamanho do texto.\n",
    "- Trocar modelo por outro gratuito (ex.: `mistralai/Mistral-7B-Instruct-v0.2`) ou rodar localmente via `Ollama`.\n",
    "- Adicionar classificação de tags automáticas (ex.: via embeddings + k‑means).\n",
    "- Integrar UI simples em Streamlit ou Gradio."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
